\chapter{Experiments} \label{chap:experiments}

In this chapter, we present the detailed setup of our experiments to evaluate the
proposed \textbf{DUP-OT} framework for non-overlapping cross-domain recommendation training.
Specifically, we first proposed the research questions we want to solve by conducting experiments,
and then we'll describe the datasets we used and how we preprocessed them, the
experiments we conducted, including the baseline models we compared against, the evaluation metrics we employed.
Finally, we outline the implementation details of our proposed method, including
hyperparameter settings and training procedures to ensure reproducibility.

The final results and analyses will be presented in the next chapter.

\section{Research Questions}
As the proposed \textbf{DUP-OT} framework introduces two key components: (1) distribution-based user preference modeling using GMMs, and (2) cross-domain preference transfer via optimal transport,
we want to design experiments to figure out the effects of these two components respectively.
Moreover, we also want to compare our proposed method with existing non-overlapping cross-domain recommendation methods.
Thus, the research questions we aim to answer through our experiments can be summarized as follows:
\begin{itemize}
	\item \textbf{RQ1:} Does introducing cross-domain information enhance the recommendation performance in the target domain?
	\item \textbf{RQ2:} Does modeling user preferences as distributions, rather than vectors, lead to improved recommendation performance?
	\item \textbf{RQ3:} How does the performance of our proposed method compare with that of existing non-overlapping CDR models?
\end{itemize}

To answer \textbf{RQ1}, we conduct an ablation study comparing target-domain recommendation performance with and without leveraging
source-domain information. When we do not use source-domain data, our model essentially reduces to a single-domain recommendation model that employs GMMs for user preference modeling.

To address \textbf{RQ2}, we evaluate our target-domain model without source-domain information against
some single-domain baseline models that represent user preferences as vectors.
The idea is, if we don't use source-domain data, the target-domain model will reduce to a single-domain recommendation model,
and thus the only difference between our model and the baselines will be the way of user preference modeling.
Thus we can isolate the effect of distribution-based user preference modeling.

Finally, to answer \textbf{RQ3}, we simply compare our full model with representative non-overlapping CDR baseline models
in the same experimental settings.

\section{Datasets and Preprocessing}
We set our experiment under an e-commerce scenario, where different product categories are treated as different domains.
For example, Electronics and Video Games are two different domains, and our target is to leverage user interactions in the source domain (e.g., Video Games)
to improve recommendation performance in the target domain (e.g., Electronics).
To this end, we choose the Amazon Review dataset~\cite{Ni_Li_McAuley_2019_Justifying_Recommendations} for our experiments,
specifically, we choose the 5-core version of four domains: Electronics, Digital Music, Movies \& TV, and Video Games.
To make sure the 5-core really holds in these four datasets, we further filter the datasets to ensure that each user and item has at least 5 interactions.
After preprocessing, the statistics of the four datasets are summarized in Table~\ref{tab:dataset_stats}.

\begin{table}[h]
	\centering
	\caption{Statistics of the Amazon Review datasets after preprocessing.}
	\label{tab:dataset_stats}
	\begin{tabular}{lrrrr}
		\toprule
		Domain        & Users   & Items   & Interactions & Density (\%) \\
		\midrule
		Electronics   & 728,489 & 159,729 & 6,737,580    & 0.0058       \\
		Digital Music & 16,252  & 11,269  & 166,942      & 0.0912       \\
		Movies \& TV  & 297,377 & 59,925  & 3,408,612    & 0.0191       \\
		Video Games   & 55,144  & 17,286  & 496,904      & 0.0521       \\
		\bottomrule
	\end{tabular}
\end{table}

Considering the interaction density and the relative time stamps of the four domains,
we select Electronics as the target domain, and the other three domains as source domains in our experiments.

Although our proposed method is not a sequential recommendation model, we think it's still important to avoid data leakage
when splitting the datasets into training, validation, and test sets. So we sort the interactions of each user by their time stamps,
and then split target-domain interactions, in our case, Electronics, into training, validation, and test sets globally by the ratio of 80\%, 10\%, and 10\%.
Then to avoid data leakage, we need to ensure the interactions in the source domain used for training happened before
the earliest interaction in the target-domain validation set. To this end, we first find the earliest time stamp $t_{val}$ in the target-domain validation set,
and then filter the source-domain interactions to only keep those happened before $t_{val}$.
To reduce computational costs, we search for $t_{val}$ in a step of 5\% in the time-stamp sorted source-domain interactions.
We don't need to split the source-domain interactions into training, validation, and test sets,
as we only use source-domain data for training in our experiments.

As we split the interactions of target-domain globally, it's possible that some users only appear in the validation or test sets.
When we build the Dataset object for training, we just randomly set the embeddings of the users who only appear in the validation or test sets as random vectors.

\section{Experimental Setup}
To answer the research questions proposed above, we mainly design three groups of experiments
corresponding to \textbf{RQ1}, \textbf{RQ2}, and \textbf{RQ3} respectively.
All experiments are conducted on the preprocessed Amazon Review datasets described in the previous section, and
the target domain is always Electronics while the source domain varies among Digital Music, Movies \& TV, and Video Games.
In other words, we conduct experiments on three source-target domain pairs:
\begin{itemize}
	\item Digital Music $\rightarrow$ Electronics
	\item Movies \& TV $\rightarrow$ Electronics
	\item Video Games $\rightarrow$ Electronics
\end{itemize}

To answer \textbf{RQ1}, which investigates the effect of cross-domain information,
we compare two variants of our proposed framework: DUP-OT (w/ source) and DUP-OT (w/o source),
which means we either leverage source-domain information for target-domain recommendation or not.
These two variants share identical architectures, representation learning strategies, and training protocols.
The only difference lies in whether source-domain preference distributions are transferred to the target domain via optimal transport
in the last stage of our framework.
Therefore, performance differences can be directly attributed to the effect of cross-domain information.

To address \textbf{RQ2}, which examines the effect of distribution-based user preference modeling,
we compare DUP-OT (w/o source) with representative single-domain recommendation models,
namely LightGCN~\cite{He_Deng_Wang_Li_Zhang_Wang_2020_LightGCN} and NeuMF~\cite{He_Liao_Zhang_Nie_Hu_Chua_2017_NCF}.
In this setting, DUP-OT (w/o source) does not leverage any source-domain interactions and is trained exclusively on the target-domain training set.
Despite this, the only difference between DUP-OT (w/o source) and the baselines is the way of user preference modeling.
Our model represents user preferences as GMMs, while the baselines use point embeddings.
Thus, performance differences can be directly attributed to the effect of distribution-based user preference modeling.

Finally, to answer \textbf{RQ3}, which compares our proposed method with existing non-overlapping CDR models,
we select a representative non-overlapping CDR baseline model, TDAR~\cite{Yu_Lin_Ge_Ou_Qin_2020_TDAR},
and compare it with our full model, DUP-OT (w/ source), in the same experimental settings.

\subsection{Baseline Models}

As discussed in the previous section, we select different baseline models
to answer the proposed research questions from complementary perspectives.
In particular, the selected baselines cover both single-domain
recommendation models and representative non-overlapping cross-domain
recommendation approaches.
In total, we consider three baseline models and two variants of our
proposed framework in the experiments, which are described as follows:
\begin{itemize}

	\item \textbf{LightGCN}~\cite{He_Deng_Wang_Li_Zhang_Wang_2020_LightGCN}:
	      LightGCN is a representative graph-based collaborative filtering model
	      that learns user and item representations by propagating embeddings on
	      the user--item interaction graph.
	      Unlike earlier GCN-based recommenders, LightGCN removes feature
	      transformation and non-linear activation, and retains only neighborhood
	      aggregation, resulting in a simple yet effective architecture.
	      As a strong single-domain baseline, LightGCN represents user preferences
	      as deterministic embedding vectors and relies solely on target-domain
	      interaction data.
	      We include LightGCN to evaluate whether distribution-based user
	      preference modeling provides advantages over state-of-the-art
	      vector-based graph collaborative filtering methods.

	\item \textbf{NeuMF}~\cite{He_Liao_Zhang_Nie_Hu_Chua_2017_NCF}:
	      NeuMF is a classical neural collaborative filtering model that unifies
	      matrix factorization and multi-layer perceptrons under a neural
	      framework.
	      By replacing the inner product with a non-linear interaction function,
	      NeuMF aims to capture complex user--item interaction patterns in the
	      latent space.
	      Similar to LightGCN, NeuMF represents users and items as point-valued
	      latent vectors and operates in a purely single-domain setting.
	      This baseline is adopted to compare our distribution-based user
	      preference modeling with a widely used neural vector-based
	      recommendation paradigm.

	\item \textbf{TDAR}~\cite{Yu_Lin_Ge_Ou_Qin_2020_TDAR}:
	      TDAR is a representative non-overlapping cross-domain recommendation
	      model based on text-enhanced domain adaptation.
	      In the absence of shared users or items across domains, TDAR leverages
	      domain-invariant textual features extracted from user reviews as anchor
	      points to align latent spaces via adversarial training.
	      By transferring distribution patterns learned from a dense source
	      domain to a sparse target domain, TDAR alleviates data sparsity in
	      non-overlapping scenarios.
	      We include TDAR as a strong non-overlapping CDR baseline to compare
	      our optimal transport-based preference transfer mechanism with
	      existing text-driven domain adaptation approaches.

	\item \textbf{DUP-OT (w/ source)}:
	      This variant corresponds to the full version of our proposed
	      \textbf{DUP-OT} framework.
	      It models user preferences as Gaussian mixture distributions and
	      transfers such distributional preferences from the source domain to
	      the target domain via optimal transport.
	      This setting evaluates the complete effectiveness of distribution-based
	      preference modeling combined with cross-domain knowledge transfer.

	\item \textbf{DUP-OT (w/o source)}:
	      This variant disables the cross-domain transfer component and trains
	      the model using only target-domain data.
	      Under this setting, DUP-OT degenerates into a single-domain
	      recommendation model that still represents user preferences as
	      probability distributions.
	      By comparing this variant with vector-based single-domain baselines,
	      we can isolate and analyze the impact of distribution-based user
	      preference modeling independent of cross-domain information.

\end{itemize}

\subsection{Evaluation Metrics}

To quantitatively assess the recommendation performance of different models,
we formulate the recommendation task as a \emph{rating prediction} problem
and employ two widely used evaluation metrics: Root Mean Square Error (RMSE)
and Mean Absolute Error (MAE).

We adopt rating prediction as the evaluation task for two main reasons.
First, rating prediction provides a fine-grained and direct measure of how
accurately a model captures user preferences, which is particularly important
in cross-domain recommendation scenarios where the goal is to transfer
preference knowledge from a source domain to a target domain.
Second, in non-overlapping cross-domain recommendation settings, ranking-based
evaluation protocols often rely on strong assumptions about negative sampling
and candidate item sets, which may introduce additional bias.
In contrast, rating prediction allows us to evaluate model performance on
observed user--item interactions without requiring assumptions about
unobserved entries.

Following prior cross-domain recommendation studies that focus on rating
prediction under non-overlapping settings, we adopt RMSE and MAE as our
primary evaluation metrics.
Both metrics have been widely used in existing cross-domain recommendation
work and provide complementary perspectives on prediction accuracy.
RMSE penalizes large prediction errors more heavily and is therefore sensitive
to outliers, while MAE measures the average absolute deviation and offers a
more robust assessment of overall prediction quality.

Formally, given a set of test user--item interactions
$\mathcal{D}_{test} = \{(u, i, r_{ui})\}$,
where $r_{ui}$ denotes the ground-truth rating of user $u$ on item $i$,
the RMSE and MAE are defined as follows:
\begin{equation}
	\text{RMSE} = \sqrt{\frac{1}{|\mathcal{D}_{test}|}
		\sum_{(u, i, r_{ui}) \in \mathcal{D}_{test}} (\hat{r}_{ui} - r_{ui})^2}
\end{equation}
\begin{equation}
	\text{MAE} = \frac{1}{|\mathcal{D}_{test}|}
	\sum_{(u, i, r_{ui}) \in \mathcal{D}_{test}} |\hat{r}_{ui} - r_{ui}|
\end{equation}
where $\hat{r}_{ui}$ denotes the predicted rating generated by a recommendation
model.
Lower values of RMSE and MAE indicate better recommendation accuracy.

\section{Implementation Details}
In this section, we provide implementation details of our proposed \textbf{DUP-OT} framework
to ensure reproducibility of our experimental results.

We implement our model using PyTorch and conduct experiments on a machine with an NVIDIA RTX 3080 GPU.
To retrieve user and item embeddings from the interaction data, we utilize a pre-trained BERT model to encode from review texts.
Specifically, we use the \texttt{all-MiniLM-L6-v2} variant from the Sentence Transformers library~\cite{Reimers_Gurevych_2019_SBERT},
which produces 384-dimensional embeddings.

To reduce computational costs, we trained an auto-encoder to compress the 384-dimensional BERT embeddings into 128-dimensional vectors.
Specifically, to ensure both domains' embeddings remain in the same latent space, we train the auto-encoder
on both source and target domain user and item embeddings together.
The auto-encoder consists of an encoder with two linear layers (384 $\rightarrow$ 256 $\rightarrow$ 128),
and a decoder with two linear layers (128 $\rightarrow$ 256 $\rightarrow$ 384). And we use
ReLU as the activation function between layers.
For training the auto-encoder, we use the Adam optimizer with a learning rate of 0.0002 and a batch size of 128.
We set the number of training epochs to 500 and use Mean Squared Error (MSE) as the reconstruction loss.

In the proposed \textbf{DUP-OT} framework, we fit Gaussian Mixture Models (GMMs)
on item embeddings separately for each domain in order to capture the latent
multi-modal structure of item representations.

Specifically, we employ the \texttt{BayesianGaussianMixture} class from the
\texttt{sklearn.mixture} module in Scikit-learn~\cite{scikit-learn}. For each
domain, the maximum number of mixture components is set to the square root of
the number of items in that domain, with a lower bound of 8 and an upper bound of
128. This heuristic provides sufficient modeling capacity while avoiding
excessive complexity in domains with large item sets. The final effective number
of components is inferred automatically through variational Bayesian inference.

We set the maximum number of iterations to 300 and adopt a diagonal covariance
structure (\texttt{covariance\_type = 'diag'}), which offers a good trade-off
between expressive power and computational efficiency. Diagonal covariances are
sufficient to capture variations along individual embedding dimensions while
maintaining numerical stability and scalability.

To further ensure stable optimization, we add a small regularization term
(\texttt{reg\_covar = 1e-5}) to the diagonal of each covariance matrix. The
convergence tolerance is set to \texttt{tol = 1e-3}. We use the default setting
for the weight concentration prior, and fix \texttt{random\_state = 42} to ensure
reproducibility. Verbose output is disabled during model fitting.

After obtaining the Gaussian Mixture Models for both the source and target
domains, we compute a pairwise Wasserstein distance matrix between the Gaussian
components across domains. This distance matrix serves as the cost matrix for
cross-domain alignment.

Based on this cost matrix, we formulate the optimal transport problem between
source-domain and target-domain preference distributions. The optimal transport
plan is computed using the Python Optimal Transport (POT) library~\cite{POT_2021}.

In the next stage of our framework, we need to train two MLPs in each domain, one
for learning the user preference weights over GMM components,
and the other for predicting ratings based on user preference distributions and
item embeddings.

We train each domain's MLPs separately using the Adam optimizer with a learning rate of 0.0003 and a batch size of 256.
To make the final result more convincing, we repeated each experiment 5 times with different random seeds and report the average performance.
The random seed is set to 7, 11, 17, 33, 2025 for different runs.
The total epochs for training are set to 50 for both source and target domains.
For the MLP architecture, both MLPs consist of three linear layers with ReLU activation functions between layers.
The first MLP takes dimensional-reduced user embeddings as input and outputs preference weights for each GMM component in the corresponding domain.
The shape of the first MLP is (128, (128 +  number of GMM components)//2, number of GMM components).
The second MLP takes as input the Mahalanobis distances between the item
embedding and each Gaussian component, weighted by the corresponding
user-specific mixture weights, together with a processed timestamp feature,
and outputs the predicted rating.
The shape of the second MLP is (number of GMM components + 1, (number of GMM components + 1)//2, 1).

For the timestamp feature, we transform the original interaction time into a
normalized recency-aware scalar to capture temporal effects in user behavior.
Specifically, for each domain, we use the maximum timestamp observed in the
training set as a reference time. Given an interaction occurring at time $t$,
we first compute its temporal distance to the reference time in units of months.
To avoid extreme values caused by very old interactions, this temporal distance
is capped at a maximum of 36 months.

We then apply an exponential decay function to model temporal recency, where the
decay rate is chosen such that the weight decays to $0.5$ after six months.
Formally, the decayed time value is computed as $\exp(-\lambda \Delta t)$, where
$\Delta t$ denotes the clipped month-level time difference and $\lambda$ is the
decay coefficient. Finally, the resulting value is passed through a squashing
transformation $x / (1 + x)$ to obtain a bounded and smooth timestamp feature.

The same reference time derived from the training set is used to process
validation and test interactions, ensuring temporal consistency and preventing
information leakage. The processed timestamp feature is then concatenated with
the distance-based representation and fed into the rating prediction MLP.

Finally, in the test phase, we consider different availability patterns of
user preference information across the source and target domains. Specifically,
test users are categorized into the following three cases:
\begin{itemize}
	\item Users who appear only in the target-domain test set.
	\item Users who appear only in the source-domain test set.
	\item Users who appear in both the source-domain and target-domain test sets.
\end{itemize}

For users who appear only in the target-domain test set, we directly use the
trained target-domain model to infer their preference weights over the target
GMM components and make rating predictions accordingly.

For users who appear only in the source-domain test set, we first use the trained
source-domain model to infer their preference weights over the source-domain GMM
components. These source-domain mixture weights are then mapped to the target
domain via the learned optimal transport plan, yielding transferred preference
weights on the target-domain GMM components. The transferred weights are finally
used by the target-domain rating predictor to make rating predictions.

For users who appear in both source and target domains, we infer their
domain-specific preference weights using the corresponding trained models.
Specifically, let $\mathbf{w}_u^{tgt, raw}$ denote the preference weight vector
over target-domain GMM components inferred from target-domain interactions, and
let $\mathbf{w}_u^{tgt, trans}$ denote the preference weight vector transferred
from the source domain via optimal transport. We then combine the two weight
vectors as follows:
\begin{equation}
	\mathbf{w}_u^{tgt} = \alpha \mathbf{w}_u^{tgt, raw}
	+ (1 - \alpha)\mathbf{w}_u^{tgt, trans},
\end{equation}
where $\alpha$ controls the relative contribution of target-domain and
source-domain information. In our experiments, we set $\alpha = 0.5$ to assign
equal importance to both sources. The combined preference weights
$\mathbf{w}_u^{tgt}$ are subsequently normalized and fed into the trained
target-domain rating prediction MLP to produce the final rating predictions, from
which RMSE and MAE are computed.