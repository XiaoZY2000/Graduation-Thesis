\chapter{Preliminaries}\label{chap:premilinaries}

\section{Recommender Systems}
% Mathematical modeling of the task of recommender systems
Recommender systems can be mathmatically modeled as a function $R: U \times I \rightarrow S$, where $U$ is the set of users, $I$ is the set of items, and $S$ is the set of possible scores or ratings. The goal of a recommender system is to predict the score $s \in S$ that a user $u \in U$ would give to an item $i \in I$. This prediction can be represented as $\hat{s} = R(u, i)$. The final task of recommender systems is to generate a ranked list of items for each user based on the predicted scores.

\section{Cross-Domain Recommendation}
% Mathematical modeling of the task of cross-domain recommendation
Cross-domain recommendation aims to leverage user preferences and behaviors from one or more source domains to improve recommendation performance in a target domain. Formally, let $D_s$ be the source domain with user set $U_s$ and item set $I_s$, and $D_t$ be the target domain with user set $U_t$ and item set $I_t$. The objective is to learn a recommendation function $R_t: U_t \times I_t \rightarrow S$ for the target domain by utilizing information from the source domain(s) $D_s$.
The infromation that can be transferred from the source domain to the target domain includes user-item interactions, user profiles, item attributes, and latent factors learned from the source domain. The challenge in cross-domain recommendation lies in effectively transferring knowledge while addressing issues such as domain heterogeneity, data sparsity, and cold-start problems.

\section{Gaussian Mixture Models}
% Mathematical definition of Gaussian Mixture Models
A Gaussian Mixture Model (GMM) is a probabilistic model that assumes data is generated from a mixture of several Gaussian distributions. Formally, a GMM can be represented as:
\begin{equation}
	p(x) = \sum_{k=1}^{K} \pi_k \mathcal{N}(x | \mu_k, \Sigma_k)
\end{equation}
where $K$ is the number of Gaussian components, $\pi_k$ are the mixture weights satisfying $\sum_{k=1}^{K} \pi_k = 1$, and $\mathcal{N}(x | \mu_k, \Sigma_k)$ is the Gaussian distribution with mean $\mu_k$ and covariance matrix $\Sigma_k$.

\section{Optimal Transport}
% Mathematical definition of Optimal Transport, and the variant we are using in our proposed method
Optimal transport is a mathematical framework for comparing and transforming probability distributions. Given two probability distributions $\mu$ and $\nu$ defined on spaces $X$ and $Y$, respectively, the optimal transport problem seeks to find a mapping $T: X \rightarrow Y$ that minimizes the cost of transporting mass from $\mu$ to $\nu$. The cost function $c(x, y)$ quantifies the expense of moving mass from point $x \in X$ to point $y \in Y$. The optimal transport problem can be formulated as:
\begin{equation}
	\min_{T} \int_{X} c(x, T(x)) d\mu(x)
\end{equation}
subject to the constraint that the pushforward measure $T_{\#}\mu = \nu$.
Optimal transport has been widely used in various applications, including image processing, machine learning, and economics, due to its ability to capture the geometric structure of probability distributions.
In our proposed method, we are not using optimal transport in the standard sense above, but using a related concept called Wasserstein distance to measure the distance between two probability distributions. The Wasserstein distance is defined as:
\begin{equation}
	W_p(\mu, \nu) = \left( \inf_{\gamma \in \Pi(\mu, \nu)} \int_{X \times Y} c(x, y)^p d\gamma(x, y) \right)^{1/p}
\end{equation}
where $\Pi(\mu, \nu)$ is the set of all joint distributions (couplings) with marginals $\mu$ and $\nu$, and $c(x, y)$ is the cost function. The Wasserstein distance provides a meaningful way to compare probability distributions, taking into account the underlying geometry of the data.
With the distance between two probability distributions defined, we can replace the conventional pointwise distance (e.g., Euclidean distance) between vectors with the Wasserstein distance between the corresponding distributions in our proposed method.
